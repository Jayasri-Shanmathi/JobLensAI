import os
import pandas as pd
import streamlit as st
import scraper  # make sure scraper.py is in the same folder

st.set_page_config(page_title="JobLens AI", layout="wide")

def load_data(force_refresh=False):
    # If refresh button clicked or jobs.csv missing/empty â†’ run scraper
    if force_refresh or not os.path.exists("jobs.csv") or os.path.getsize("jobs.csv") == 0:
        st.info("ğŸ“¡ Fetching latest job postings...")
        scraper.scrape_jobs()

    # Try loading data safely
    if os.path.exists("jobs.csv") and os.path.getsize("jobs.csv") > 0:
        return pd.read_csv("jobs.csv")
    else:
        st.warning("âš ï¸ No job data available. Please try again later.")
        return pd.DataFrame(columns=["title", "company", "location", "stack"])

# Sidebar
st.sidebar.header("âš™ï¸ Controls")
refresh = st.sidebar.button("ğŸ”„ Refresh Jobs")

# Load data (force refresh if button clicked)
df = load_data(force_refresh=refresh)

# Title
st.title("ğŸ’¼ JobLens AI - Job Trends Dashboard")

if not df.empty:
    # Sidebar filters
    st.sidebar.header("ğŸ” Filters")
    locations = st.sidebar.multiselect("Filter by Location", options=df["location"].unique())
    stacks = st.sidebar.multiselect("Filter by Stack", options=df["stack"].unique())

    filtered_df = df.copy()
    if locations:
        filtered_df = filtered_df[filtered_df["location"].isin(locations)]
    if stacks:
        filtered_df = filtered_df[filtered_df["stack"].isin(stacks)]

    st.write(f"### Showing {len(filtered_df)} job postings")
    st.dataframe(filtered_df)

    # Job counts by location
    st.subheader("ğŸ“ Job Distribution by Location")
    st.bar_chart(filtered_df["location"].value_counts())

    # Job counts by stack
    st.subheader("ğŸ› ï¸ Job Distribution by Tech Stack")
    st.bar_chart(filtered_df["stack"].value_counts())
else:
    st.error("No job postings found. Please try again later.")
